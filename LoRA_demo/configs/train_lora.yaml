# LoRA/QLoRA 微调配置模板
model_name_or_path: "your-hf-model-name"
output_dir: "output/lora"
dataset_path: "data/train.jsonl"
per_device_train_batch_size: 4
epochs: 3
learning_rate: 2e-4
max_seq_length: 512
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
fp16: true 